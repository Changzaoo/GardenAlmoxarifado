/**
 * Sistema Global de Otimiza√ß√£o de Carregamento de Dados
 * 
 * Este m√≥dulo fornece fun√ß√µes otimizadas para carregamento r√°pido de dados do Firestore
 * Implementa:
 * - Carregamento paralelo com Promise.all
 * - Cache em mem√≥ria com TTL
 * - Pr√©-carregamento inteligente
 * - Lazy loading
 * - Batch reads
 * - √çndices otimizados
 */

import { 
  collection, 
  getDocs, 
  getDoc,
  doc,
  query, 
  where, 
  orderBy, 
  limit,
  startAfter,
  documentId
} from 'firebase/firestore';
import { db } from '../firebaseConfig';

// ==================== CACHE SYSTEM ====================

class DataCache {
  constructor() {
    this.cache = new Map();
    this.timestamps = new Map();
    this.TTL = 5 * 60 * 1000; // 5 minutos padr√£o
  }

  set(key, value, ttl = this.TTL) {
    this.cache.set(key, value);
    this.timestamps.set(key, Date.now() + ttl);
  }

  get(key) {
    const timestamp = this.timestamps.get(key);
    if (!timestamp || Date.now() > timestamp) {
      this.cache.delete(key);
      this.timestamps.delete(key);
      return null;
    }
    return this.cache.get(key);
  }

  has(key) {
    return this.get(key) !== null;
  }

  invalidate(key) {
    this.cache.delete(key);
    this.timestamps.delete(key);
  }

  invalidatePattern(pattern) {
    const regex = new RegExp(pattern);
    for (const key of this.cache.keys()) {
      if (regex.test(key)) {
        this.invalidate(key);
      }
    }
  }

  clear() {
    this.cache.clear();
    this.timestamps.clear();
  }

  getStats() {
    return {
      size: this.cache.size,
      keys: Array.from(this.cache.keys())
    };
  }
}

const globalCache = new DataCache();

// ==================== PARALLEL LOADING ====================

/**
 * Carrega m√∫ltiplas cole√ß√µes em paralelo
 * @param {Array<{name: string, query?: any}>} collections - Array de cole√ß√µes para carregar
 * @param {Object} options - Op√ß√µes de cache e timeout
 * @returns {Promise<Object>} - Objeto com dados de todas as cole√ß√µes
 */
export const loadCollectionsParallel = async (collections, options = {}) => {
  const { 
    useCache = true, 
    cacheTTL = 5 * 60 * 1000,
    timeout = 10000 
  } = options;

  console.time('‚ö° Carregamento Paralelo');

  try {
    const promises = collections.map(async ({ name, query: customQuery, transform }) => {
      const cacheKey = `collection_${name}_${customQuery ? JSON.stringify(customQuery) : 'all'}`;

      // Verificar cache
      if (useCache && globalCache.has(cacheKey)) {
        console.log(`üì¶ Cache HIT: ${name}`);
        return { name, data: globalCache.get(cacheKey), fromCache: true };
      }

      // Buscar do Firestore
      console.log(`üîç Carregando ${name}...`);
      const startTime = Date.now();

      let snapshot;
      if (customQuery) {
        snapshot = await getDocs(customQuery);
      } else {
        snapshot = await getDocs(collection(db, name));
      }

      let data = snapshot.docs.map(doc => ({ id: doc.id, ...doc.data() }));

      // Aplicar transforma√ß√£o se fornecida
      if (transform && typeof transform === 'function') {
        data = transform(data);
      }

      const loadTime = Date.now() - startTime;
      console.log(`‚úÖ ${name} carregado em ${loadTime}ms (${data.length} docs)`);

      // Salvar no cache
      if (useCache) {
        globalCache.set(cacheKey, data, cacheTTL);
      }

      return { name, data, fromCache: false, loadTime };
    });

    // Executar todas as queries em paralelo com timeout
    const results = await Promise.race([
      Promise.all(promises),
      new Promise((_, reject) => 
        setTimeout(() => reject(new Error('Timeout ao carregar dados')), timeout)
      )
    ]);

    console.timeEnd('‚ö° Carregamento Paralelo');

    // Converter array de resultados em objeto
    const resultObject = {};
    const stats = {
      total: results.length,
      fromCache: 0,
      fromFirestore: 0,
      totalLoadTime: 0
    };

    results.forEach(({ name, data, fromCache, loadTime }) => {
      resultObject[name] = data;
      if (fromCache) {
        stats.fromCache++;
      } else {
        stats.fromFirestore++;
        stats.totalLoadTime += loadTime || 0;
      }
    });

    console.log('üìä Stats:', stats);

    return { data: resultObject, stats };

  } catch (error) {
    console.error('‚ùå Erro no carregamento paralelo:', error);
    throw error;
  }
};

// ==================== BATCH READS ====================

/**
 * Carrega m√∫ltiplos documentos por ID em batch
 * Mais eficiente que m√∫ltiplos getDoc individuais
 */
export const loadDocumentsBatch = async (collectionName, docIds, options = {}) => {
  const { useCache = true, cacheTTL = 5 * 60 * 1000 } = options;

  if (!docIds || docIds.length === 0) return [];

  console.time(`‚ö° Batch load ${collectionName}`);

  try {
    // Verificar cache primeiro
    const cachedDocs = [];
    const uncachedIds = [];

    docIds.forEach(id => {
      const cacheKey = `doc_${collectionName}_${id}`;
      if (useCache && globalCache.has(cacheKey)) {
        cachedDocs.push(globalCache.get(cacheKey));
      } else {
        uncachedIds.push(id);
      }
    });

    console.log(`üì¶ Cache: ${cachedDocs.length}/${docIds.length}`);

    // Se todos est√£o no cache, retornar
    if (uncachedIds.length === 0) {
      console.timeEnd(`‚ö° Batch load ${collectionName}`);
      return cachedDocs;
    }

    // Carregar os que n√£o est√£o no cache (batch de at√© 10 por vez - limita√ß√£o do Firestore)
    const batchSize = 10;
    const batches = [];
    for (let i = 0; i < uncachedIds.length; i += batchSize) {
      batches.push(uncachedIds.slice(i, i + batchSize));
    }

    const batchResults = await Promise.all(
      batches.map(async (batch) => {
        const q = query(
          collection(db, collectionName),
          where(documentId(), 'in', batch)
        );
        const snapshot = await getDocs(q);
        return snapshot.docs.map(doc => ({ id: doc.id, ...doc.data() }));
      })
    );

    const newDocs = batchResults.flat();

    // Salvar no cache
    if (useCache) {
      newDocs.forEach(doc => {
        const cacheKey = `doc_${collectionName}_${doc.id}`;
        globalCache.set(cacheKey, doc, cacheTTL);
      });
    }

    console.timeEnd(`‚ö° Batch load ${collectionName}`);

    return [...cachedDocs, ...newDocs];

  } catch (error) {
    console.error(`‚ùå Erro no batch load de ${collectionName}:`, error);
    throw error;
  }
};

// ==================== LAZY LOADING / PAGINATION ====================

/**
 * Carrega dados com pagina√ß√£o para grandes cole√ß√µes
 */
export const loadPaginated = async (collectionName, options = {}) => {
  const {
    pageSize = 50,
    orderByField = 'criadoEm',
    orderDirection = 'desc',
    filters = [],
    lastDoc = null
  } = options;

  try {
    let q = collection(db, collectionName);

    // Aplicar filtros
    filters.forEach(({ field, operator, value }) => {
      q = query(q, where(field, operator, value));
    });

    // Ordena√ß√£o
    q = query(q, orderBy(orderByField, orderDirection));

    // Pagina√ß√£o
    if (lastDoc) {
      q = query(q, startAfter(lastDoc));
    }

    q = query(q, limit(pageSize));

    const snapshot = await getDocs(q);
    const data = snapshot.docs.map(doc => ({ id: doc.id, ...doc.data() }));
    const lastVisible = snapshot.docs[snapshot.docs.length - 1];

    return {
      data,
      lastDoc: lastVisible,
      hasMore: data.length === pageSize
    };

  } catch (error) {
    console.error(`‚ùå Erro ao carregar p√°gina de ${collectionName}:`, error);
    throw error;
  }
};

// ==================== PR√â-CARREGAMENTO INTELIGENTE ====================

/**
 * Pr√©-carrega dados que provavelmente ser√£o necess√°rios
 */
export const preloadData = async (collections) => {
  console.log('üöÄ Pr√©-carregando dados...');
  
  const promises = collections.map(async ({ name, query: customQuery }) => {
    try {
      const cacheKey = `collection_${name}_preload`;
      
      if (globalCache.has(cacheKey)) {
        return;
      }

      const snapshot = await getDocs(customQuery || collection(db, name));
      const data = snapshot.docs.map(doc => ({ id: doc.id, ...doc.data() }));
      
      globalCache.set(cacheKey, data);
      console.log(`‚úÖ Pr√©-carregado: ${name} (${data.length} docs)`);
    } catch (error) {
      console.warn(`‚ö†Ô∏è Erro ao pr√©-carregar ${name}:`, error);
    }
  });

  await Promise.allSettled(promises);
  console.log('üéâ Pr√©-carregamento conclu√≠do');
};

// ==================== UTILITIES ====================

/**
 * Limpa cache seletivamente
 */
export const invalidateCache = (pattern) => {
  if (pattern) {
    globalCache.invalidatePattern(pattern);
    console.log(`üßπ Cache invalidado: ${pattern}`);
  } else {
    globalCache.clear();
    console.log('üßπ Cache totalmente limpo');
  }
};

/**
 * Obt√©m estat√≠sticas do cache
 */
export const getCacheStats = () => {
  return globalCache.getStats();
};

/**
 * Carrega cole√ß√£o √∫nica com cache
 */
export const loadCollection = async (collectionName, options = {}) => {
  const { useCache = true, cacheTTL, transform, filters = [] } = options;
  
  const cacheKey = `collection_${collectionName}_${JSON.stringify(filters)}`;

  if (useCache && globalCache.has(cacheKey)) {
    console.log(`üì¶ Cache HIT: ${collectionName}`);
    return globalCache.get(cacheKey);
  }

  console.time(`‚ö° Load ${collectionName}`);

  try {
    let q = collection(db, collectionName);

    // Aplicar filtros
    filters.forEach(({ field, operator, value }) => {
      q = query(q, where(field, operator, value));
    });

    const snapshot = await getDocs(q);
    let data = snapshot.docs.map(doc => ({ id: doc.id, ...doc.data() }));

    // Aplicar transforma√ß√£o
    if (transform) {
      data = transform(data);
    }

    if (useCache) {
      globalCache.set(cacheKey, data, cacheTTL);
    }

    console.timeEnd(`‚ö° Load ${collectionName}`);
    console.log(`‚úÖ ${collectionName}: ${data.length} documentos`);

    return data;

  } catch (error) {
    console.error(`‚ùå Erro ao carregar ${collectionName}:`, error);
    throw error;
  }
};

// ==================== EXPORTS ====================

export {
  globalCache,
  DataCache
};

export default {
  loadCollectionsParallel,
  loadDocumentsBatch,
  loadPaginated,
  preloadData,
  invalidateCache,
  getCacheStats,
  loadCollection
};
